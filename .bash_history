ls
whoami
bin/crawl urls/seed.txt TestCrawl http://dev-crawler.wrl.org:8983/solr/ 2
pwd
cd apache-nutch-1.7/
bin/crawl urls/seed.txt TestCrawl http://dev-crawler.wrl.org:8983/solr/ 2
locate hadoop.log
cat /opt/apache-nutch-1.7/logs/hadoop.log
bin/crawl urls/seed.txt TestCrawl http://dev-crawler.wrl.org:8983/solr/ 2
history |more
bin/nutch crawl urls -dir crawl -depth 3 -topN 5
pwd
cd ..
ls
cd apache-ant-1.9.2/
ls
cd etc
ls
cd ..
ls
vi fetch.xml 
ls
cd ..
ls
rm -r -f rh
ls
cd apache-nutch-1.7/
ls
cd conf
ls
ni nutch-default.xml 
vi nutch-default.xml 
hostname
exit
cd /opt/apache-nutch-1.7/
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 2
bin/nutch crawl urls -dir crawl -depth 3 -topN 5
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 2
bin/crawl urls/seed.txt TestCrawl http://dev-crawler.wrl.org:8983/solr/collection1 2
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 2
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
ls
vi urls
cd urls
ls
vi seed.txt 
cd ..
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 2
pwd
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 5
cd urls/
ls
vi seed.txt 
cd ..
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 2
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
bin/nutch crawl urls -dir crawl -depth 3 -topN 5
vi urls/seed.txt 
ls
cd conf
ls
vi domainblacklist-urlfilter.txt 
vi domain-urlfilter.txt 
ls -sla
vi domain-urlfilter.txt 
pwd
cd ..
ls
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
ls
cd crawl/
ls
rm -r -f *
cd ..
rm -r -f TestCrawl/
rm -r -f crawl/
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
ls
cd conf
ls
ls -sla
cp schema.xml /opt/solr-4.5.1/example/conf/schema.xml
ps -ax |grep start
kill 5717
ps -ax |grep start
ls
cd ..
ls
ps
ls
pwd
cd ..
ls
cd solr-4.5.1/
ls
pwd
cd example/
ls
java -jar start.jar
cd /opt/solr-4.5.1/
ls
cd example/
ls
java -jar start.jar 
nohup java -jar start.jar 
java -jar start.jar 
ls
vi nohup.out 
ls
whoami
pwd
cd solr
ls
cd bin
ls
cd ..
cd conf
ls
vi schema.xml 
ls -sla
pwd
cp /opt/apache-nutch-1.7/conf/schema-solr4.xml schema.xml
ls -sla
pwd
cd ..
ls
vi solr.xml 
cd ..
ls
java -jar start.jar 
ls
cd conf
ls
pwd
cd ..
cd solr
ls
cd conf
ls
vi schema.xml 
cd ..
ls
cd ..
ls
java -jar start.jar 
ls
cd conf
ls
ls -sla
vi schema.xml 
cd ..
ls
java -jar start.jar 
ls
cd ..
ls
cd apache-nutch-1.6
ls
cd conf
ls
cp schema-solr4.xml /opt/solr-4.5.1/example/conf/schema.xml
cp schema-solr4.xml /opt/solr-4.5.1/example/solr/conf/schema.xml
ls
cd ..
ls
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
ls
cp -R ../apache-nutch-1.7/urls .
ls
ls -sla
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
ls
cd conf
ls
vi nutch-site.xml 
vi ../../apache-nutch-1.7/conf/nutch-site.xml 
cp ../../apache-nutch-1.7/conf/nutch-site.xml .
pwd
cd ..
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
ls
cd TestCrawl/
ls
cd ..
ls
bin/nutch crawl urls -dir crawl -depth 3 -topN 5
cd ..
ls
cd solr-4.5.1/
ls
cd example/
ls
rm nohup.out 
cd conf
ls
cd ..
ls
cd solr
ls
vi solr.xml 
vi zoo.cfg 
ls
cd conf
ls
vi schema.xml 
ls
cd ..
ls
cd ..
ls
java -jar start.jar 
ls
pwd
cd conf
ls
vi schema.xml 
ls
vi schema-solr4.xml 
cd ..
ls
java -jar start.jar 
ls
cd conf
ls
cat schema.xml |grep _version
ls
cd ..
ls
cd multicore/
ls
vi solr.xml 
cd ..
ls
cd solr
ls
cd conf
ls
cat schema.xml |grep _vers
ls
cd ..
ls
cd collection1/
ls
cd conf
ls
cat schema.xml |grep _vers
vi schema.xml
cd ..
pwd
cd ..
ls
java -jar start.jar 
nohup java -jar start.jar & 
cd ..
ls
cd ..
ls
cd apache-nutch-1.6
ls
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
ls
ls- sla
ls -sla
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb crawl/segments/*
ls
pwd
vi run.sh
chmod +x run.sh
mv run.sh testrun.sh
./testrun.sh 
pwd
ls
cd urls/
ls
vi seed.txt 
ls
cd ..
ls
cd ..
cd apache-nutch-1.
cd apache-nutch-1.6/
./testrun.sh 
cd crawl
ls
cd ..
ls
vi testrun.sh 
cd TestCrawl/
ls
cd ..
rm -r -f TestCrawl
cd doc
cd docs
ls
cd ..
ls
vi README.txt 
ls
pwd
cd conf
vi regex-urlfilter.txt 
ls
cd ..
ls
./testrun.sh 
cd logs
ls
ls -sla
rm hadoop.log
cd ..
./testrun.sh 
cd log
ls
cd logs
ls
ls -sla
more hadoop.log 
cd
ls
pwd
tar -cvf /tmp/apache-nutch.tar /opt/apache-nutch-1.6
tar -cvf /tmp/apache-solr.tar /opt/solr-4.5.1
ls /opt
cd apache-ant
cd /opt/apache-ant-1.9.2/
ls
cd ..
tar -cvf /tmp/apache-ant.tar /opt/apache-ant-1.9.2
cd /tmp
ls
gzip apache-ant.tar 
gzip apache-nutch.tar 
gzip apache-solr.tar 
ls -sla
mail rein@velt.org < apache-ant.tar.gz 
mailq
mail
exit
cd /opt
ls
cd apache-nutch-1.6/
ls
cd urls
ls
vi seed.txt 
cd ..
vi testrun.sh 
./testrun.sh 
ls
cat testrun.sh 
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb crawl/segments/*
cd crawl
ls
rm -r -f *
ls
cd ..
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb crawl/segments/*
ls
rm -r -f crawl
rm -r -f tmp_1386324603990-2144565067/
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb crawl/segments/*
mkdir crawl
mkdir crawl/crawldb
mkdir crawl/linkdb
mkdir crawl/crawldb/current
mkdir crawl/linkdb/current
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb crawl/segments/*
mkdir crawl/segments
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb crawl/segments/*
history
bin/crawl urls/seed.txt TestCrawl http://localhost:8983/solr/collection1 3
bin/crawl urls/seed.txt crawl http://localhost:8983/solr/collection1 3
ls
rm -r -f TestCrawl/
cd crawl/
ls
cd segments/
ls
cd ..
ls
./testrun.sh 
vi testrun.sh 
./testrun.sh 
bin/crawl urls/seed.txt crawl http://localhost:8983/solr/collection1 5
bin/crawl urls/seed.txt crawl http://localhost:8983/solr 10
bin/crawl urls/seed.txt crawl http://localhost:8983/solr/collection1 10
vi urls/seed.txt 
bin/crawl urls/seed.txt crawl http://localhost:8983/solr/collection1 10
bin/crawl urls/seed.txt crawl http://localhost:8983/solr/collection1 5
ls
./testrun.sh 
rm -r -f crawl
ls
rm -r -f inject-temp-1455659653
./testrun.sh 
ls
cd logs
ls
ls -sla
vi hadoop.log
cd ..
ls
bin/nutch crawl urls -solr http://localhost:8983/solr/ -depth 3 -topN 5
bin/nutch crawl urls -dir crawl -depth 3 -topN 5
ls
rm -r -f crawl-20131206124610
cd crawl
ls
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/ -depth 3 -topN 5
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5
ls
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5
ls
cd urls
ls
vi seed.txt 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5
ls
rm -r -f crawl
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5
rm -r -f crawl
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5000 
rm -r -f crawl
ls
rm -r -f tmp_1386330554151--1117430026
cd urls
ls
cat seed.txt 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 500 
ls
rm -r -f crawl
cd urls/
vi seed.txt 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 500 
cd urls
vi seed.txt 

bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 500 
ls
rm -r -f crawl
cd conf
ls
vi nutch-conf.xsl 
LS
ls
vi automaton-urlfilter.txt 
cd ..
ls
wget http://dev.wrl.org/zoekindex.xml
vi zoekindex.xml 
ls
rm zoekindex.xml 
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 500 
ls
rm -r -f crawl
cd urls
vi seed.txt 
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 500 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 500 
bincd urls
ls
cd urls/
ls
vi seed.txt 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 500 
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5 
ls
cd conf
ls
vi automaton-urlfilter.txt 
cd ..
ls
cd urls
ls
vi seed.txt 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5 
ls
rm -r -f crawl
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 3 -topN 5 
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 5 -topN 50 
ls
cd urls
ls
vi seed.txt 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 5 -topN 50 
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 5 -topN 500
cd urls/
ls
vi seed.txt 
cd ..
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 5 -topN 500
ls
rm -r -f crawl
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 5 -topN 500
nohup bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 5 -topN 500
ls
cd /opt
ls
cd apache-nutch-1.6
ls
vi testrun.sh 
./testrun.sh 
nohup bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr/collection1 -depth 5 -topN 500
bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr -depth 3 -topN 500
bin/nutch inject crawl_test/crawldb seeds/
ls
bin/nutch inject crawl_test/crawldb urls/
bin/nutch generate crawl_test/crawldb crawl_test/segments
export SEGMENT=crawl_test/segments/`ls -tr crawl_test/segments|tail -1`
bin/nutch fetch $SEGMENT -noParsing
bin/nutch parse $SEGMENT
bin/nutch updatedb crawl_test/crawldb $SEGMENT -filter -normalize
bin/nutch invertlinks crawl_test/linkdb -dir crawl_test/segments
bin/nutch solrindex http://localhost:8983/solr/ crawl_test/crawldb -linkdb crawl_test/linkdb crawl_test/segments/$SEGMENT
bin/nutch solrindex http://localhost:8983/solr/ crawl_test/crawldb -linkdb crawl_test/linkdb $SEGMENT
nohup bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr -depth 2 -topN 200
 bin/nutch crawl urls -dir crawl -solr http://localhost:8983/solr -depth 2 -topN 200
cd /opt/apache-nutch-1.6/crawl/segments/20131209172347
ls
cd ..
ls
cd ..
cd .
cd ..
ls
rm -r -f crawl
rm -r -f crawl-test
vi testrun.sh 
./testrun.sh 
bin/nutch inject crawl/crawldb urls/
bin/nutch generate crawl/crawldb crawl/segments
export SEGMENT=crawl/segments/`ls -tr crawl/segments|tail -1`
bin/nutch fetch $SEGMENT 
bin/nutch updatedb crawl/crawldb $SEGMENT -filter -normalize
bin/nutch invertlinks crawl/linkdb -dir crawl/segments
ls
cd bin
ls
cd ..
ls
bin/nutch fetch $SEGMENT 
bin/nutch updatedb crawl/crawldb $SEGMENT -filter -normalize
bin/nutch invertlinks crawl/linkdb -dir crawl/segments
bin/nutch updatedb crawl/crawldb $SEGMENT -filter -normalize
bin/nutch invertlinks crawl/linkdb -dir crawl/segments
echo $SEGMENTS
echo $SEGMENT
bin/nutch invertlinks crawl/linkdb -dir $SEGMENT
bin/nutch fetch $SEGMENT 
cd $SEGMENT 
ls
cd ..
ls
cd ..
ls
cd ..
ls
bin/nutch invertlinks crawl/linkdb -dir $SEGMENT
bin/nutch invertlinks crawl/linkdb -dir crawl/segments
pwd
rm -r -f crawl
ls
rm -r -f crawl_test
bin/nutch crawl urls -dir crawl -depth 3 -topN 5
bin/nutch crawl urls -dir crawl -depth 3 -topN 50
bin/nutch crawl urls -solr http://dev-crawler.wrl.org:8983/solr/  -depth 3 -topN 50
bin/nutch crawl urls -solr http://dev-crawler.wrl.org:8983/solr/collection1  -depth 3 -topN 100
ls /tmp
df -h /tmp
bin/nutch crawl urls -dir crawl -solr http://dev-crawler.wrl.org:8983/solr/  -depth 3 -topN 50
bin/nutch inject crawl/crawldb urls
bin/nutch inject crawl/crawldb urls/seed.txt 
bin/nutch generate crawl/crawldb crawl/segments
s1=`ls -d crawl/segments/2* | tail -1`
echo $s1
bin/nutch fetch $s1

echo $s1
bin/nutch fetch $s1
bin/nutch parse $s1
bin/nutch generate crawl/crawldb crawl/segments -topN 1000
bin/nutch generate crawl/crawldb crawl/segments -depth 3 -topN 1000
bin/nutch invertlinks crawl/linkdb -dir crawl/segments
bin/nutch invertlinks crawl/linkdb -dir crawl/$1
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb crawl/segments/*
bin/nutch solrindex http://127.0.0.1:8983/solr/ crawl/crawldb -linkdb crawl/linkdb $s1
bin/nutch invertlinks crawl/linkdb -dir $s1
pwd
bin/nutch crawl urls -solr http://localhost:8983/solr/ -depth 3 -topN 1000
bin/nutch crawl urls -solr http://localhost:8983/solr/collection1 -depth 3 -topN 10000
bin/nutch crawl urls -solr http://localhost:8983/solr/collection1/ -depth 3 -topN 10000
bin/nutch crawl urls -solr http://localhost:8983/solr/ -depth 5 -topN 1000
bin/nutch crawl urls -solr http://localhost:8983/solr/ -depth 10 -topN 1000
ls
rm -r -f apache-nutch-1.7
ls -sla
tar -cvf /tmp/opt.tar /opt
ls
cd /etc/apache2
cd /etc
ls
locate rewrite.conf
cd /etc
ls
cd /etc/httpd
cd /opt/apache-nutch-1.6/
ls
cd conf
ls
vi regex-urlfilter.txt 
vi subcollections.xml 
vi automaton-urlfilter.txt 
cd /tmp
gzip opt.tar
cd
ls
mkdir drupal_feed_to_nutch_seed
cd drupal_feed_to_nutch_seed/
vi sync.sh
chmod +x sync.sh 
./sync.sh 
ls
vi zoekindex.xml 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
vi sync.py
python sync.py 
vi sync.py
python sync.py 
vi sync.py
python sync.py 
vi sync.py
ls
rm zoekindex.*
python sync.py 
ls
./sync.sh 
vi zoekindex.xml 
vi sync.py
python sync.py 
vi sync.py
python sync.py 
vi sync.py
ls
vi sync.sh
vi sync.py
vi zoekindex.xml 
vi sync.py
python sync.py
vi sync.py
python sync.py
vi sync.py
python sync.py
vi sync.py
python sync.py
rm sync.py
ls
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
./sync.sh 
vi sync.sh 
which wget
vi sync.sh 
which cat
vi sync.sh 
pwd
vi sync.sh 

vi sync.sh 
ls
vi sync.sh 
./sync.sh 
ls
cd /opt
ls
wget https://phantomjs.googlecode.com/files/phantomjs-1.9.2-source.zip
unzip phantomjs-1.9.2-source.zip 
cd phantomjs-1.9.2
ls
./build.sh
cd ..
rm -r -f phantomjs-1.9.2
ls
rm -r -f phantomjs-1.9.2-source.zip 
phantomjs
nodejs
ls
cd ..
ls
cd phantomcore/
ls
cd ..
ls
cd conf
ls -sla
cd ..
ls
cd collection1/
ls
cd conf
ls
mkdir ../../phantomcore/conf
cp -r * ../../phantomcore/conf
cd ../../phantomcore/
cd conf
ls
vi solrconfig.xml 
pwd
mkdir data
cd ..
pwd
cd conf
ls
rmdir data
cd ..
mkdir data
ls
cd ..
pwd
ls
vi solr.xml 
vi zoo.cfg 
cd collection1/
cd ..
ls
cd conf
ls
vi schema.xml 
ls
pwd
cd ..
ls
cd phantomcore/
ls
vi core.properties 
mv core.properties core.oldprops
vi core.
vi core.properties 
ls
rm core.oldprops 
vi core.properties
cd conf
ls
vi solrconfig.xml 
vi schema.xml 
pwd
cd ..
ls
rm core.properties.unloaded 
cd ..
ls
cd collection1/
ls
rm dataDir:
rm -r -f dataDir:
ls -sla
rm -r -f "  dataDir:     "/
ls
vi core.properties 
ls
cp ../phantomcore/core.properties .
vi core.properties 
ps -ax
pwd
cd ..
cd phantomcore/
ls
cd conf
ls
vi schema.xml 
ps -ax
which phantomjs
cd /opt
ls
phantomjs
ps -ax
pwd
ls
locate
cd /usr
ls
cd bin
ls
cd /usr
ls
cd local/
ls
cd bin
ls
cd ..
ls
cd ..
cd /root
ls
cd src
ls
cd 
ls
cd solr-4.5.1/
ls
cd example/
ls
cd solr
ls
cd phantomcore/
ls
cd conf
ls
vi schema.xml 
ps -ax
ssh siteinspector@mechanicape.nl
ls
cp /tmp/siteinspector.tar.gz /opt
cd /opt
ls
gunzip siteinspector.tar.gz 
ls
tar -xvf siteinspector.tar 
ls
mkdir siteinspector
mv *.php siteinspector
ls
mv checksite.sh  siteinspector
mv js siteinspector
ls
mc phantomquail.js siteinspector
mv phantomquail.js siteinspector
ls
mv drupal_feed_to_nutch_seed siteinspector
ls
cd siteinspector
ls
vi checksite.sh 
./checksite.sh http://www.overheid.nl
mkdir /tmp/quaildata
./checksite.sh http://www.overheid.nl
vi checksite.sh 
ls /tmp/quaildata/
cat /tmp/quaildata/data 
cd /opt
cd siteinspector
ls
vi phantomquail.js 
ls
./checksite.sh http://denhaag.nl
cat /tmp/quaildata/data 
cd /opt/siteinspector/
ls
vi checksite.sh 
vi phantomquail.js 
vi checksite.sh 
./checksite.sh http://denhaag.nl
which php
cd  /opt
ls
git add siteinspector
cd
wget http://mechanicape.nl:8080/solr
wget http://mechanicape.com:8080/solr
wget http://mechanicape.com
rm index.html
ls
cd siteinspector
ls
vi drupal_feed_to_nutch_seed/
cd drupal_feed_to_nutch_seed/
ls
vi sync.sh 
ls
cd ..
ls
mv drupal_feed_to_nutch_seed ..
ls -sla
cd ..
ls
vi checksite.sh 
ls
vi phantomquail.js 
ls
./checksite.sh http://denhaag.nl
vi checksite.sh 
./checksite.sh http://denhaag.nl
ls
vi checksite.sh 
/opt/phantomjs-1.9.2-linux-x86_64/bin/phantomjs --ignore-ssl-errors=yes phantomquail.js http://denhaag.nl
ls /tmp/quaildata/data 
cat  /tmp/quaildata/data 
ls
vi parseData.php 
vi phantomquail.js 
cd /opt/solr
cd /opt/solr-4.5.1/
ls
vi parseData.php 
cd /opt/siteinspector
ls
vi parseData.php 
./checksite.sh http://denhaag.nl
pwd
cd ..
cd solr-4.5.1/
ls
cd dist/
ls
cd ..
ls
cd example/
ls
cd conf
ls
cd ..
cd multicore/
ls
cd ..
ls
cd solr
ls
cd phantomcore/
ls
cd conf
ls
sftp siteinspector@siteinspector.mechanicape.nl
sftp rein@siteinspector.mechanicape.com
sftp rein@mechanicape.com
ls
pwd
cd /opt
ls
cd siteinspector
ls
./checksite.sh http://denhaag.nl
./checksite.sh http://denhaag.nl |more
!
ls
cd /opt/solr-4.5.1/
ls
cd example/
ls
cd solr
ls
cd phantomcore/
ls
cd conf
ls
vi solrconfig.xml 
vi schema.xml 
cd /opt
ls
cd  siteinspector
ls
./checksite.sh http://denhaag.nl
./checksite.sh http://denhaag.nl |more
./checksite.sh http://denhaag.nl
ls
hostname
cd /opt
cd siteinspector
./checksite.sh http://rotterdam.nl
./checksite.sh http://www.rotterdam.nl
cat /tmp/quaildata/data 
./checksite.sh http://www.gouda.nl
./checksite.sh http://www.leiden.nl
./checksite.sh http://www.zaanstad.nl
./checksite.sh http://www.delft.nl
./checksite.sh http://www.stadskanaal.nl
